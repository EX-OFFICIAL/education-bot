import os
import logging
import tempfile
import re
from telegram import Update, InputFile
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from PIL import Image, ImageEnhance, ImageOps
import pytesseract
from pdf2image import convert_from_bytes
import io
import requests
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor
import asyncio
import openai  # For AI enhancements

# Load configuration
load_dotenv()

# ğ—”ğ—±ğ˜ƒğ—®ğ—»ğ—°ğ—²ğ—± ğ—–ğ—¼ğ—»ğ—³ğ—¶ğ—´ğ˜‚ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»
class Config:
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    MAX_PAGES = 100
    LANGUAGES = {
        'english': 'eng',
        'bengali': 'ben',
        'hindi': 'hin',
        'arabic': 'ara',
        'chinese': 'chi_sim',
        'spanish': 'spa'
    }
    AI_FEATURES = {
        'translation': True,
        'summarization': True,
        'sentiment_analysis': True
    }
    PREPROCESS_METHODS = ['contrast', 'sharpness', 'denoise', 'binarization']

# Thread pool for parallel processing
executor = ThreadPoolExecutor(max_workers=6)

# ğ—”ğ—œ ğ—¦ğ—²ğ˜ğ˜‚ğ—½
openai.api_key = os.getenv("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")

# ğ—œğ—ºğ—®ğ—´ğ—² ğ—£ğ—¿ğ—²ğ—½ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ğ—¶ğ—»ğ—´ ğ—˜ğ—»ğ—´ğ—¶ğ—»ğ—²
def enhance_image(image, methods=Config.PREPROCESS_METHODS):
    """Apply multiple enhancement techniques"""
    if 'contrast' in methods:
        image = ImageEnhance.Contrast(image).enhance(1.8)
    if 'sharpness' in methods:
        image = ImageEnhance.Sharpness(image).enhance(2.2)
    if 'binarization' in methods:
        image = image.convert('1')  # Binarization
    if 'denoise' in methods:
        image = ImageOps.exif_transpose(image)
    return image

# ğ—”ğ—œ-ğ—£ğ—¼ğ˜„ğ—²ğ—¿ğ—²ğ—± ğ—™ğ—²ğ—®ğ˜ğ˜‚ğ—¿ğ—²ğ˜€
async def ai_translate(text, target_lang="english"):
    """Use AI for context-aware translation"""
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{
            "role": "system",
            "content": f"Translate this accurately to {target_lang} maintaining technical terms:"
        }, {
            "role": "user",
            "content": text
        }],
        temperature=0.3
    )
    return response.choices[0].message.content

async def ai_summarize(text, length="medium"):
    """Generate intelligent summaries"""
    prompt = f"Create a {length} summary keeping key points:\n{text}"
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return response.choices[0].message.content

# ğ— ğ—®ğ—¶ğ—» ğ—£ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ğ—¶ğ—»ğ—´ ğ—˜ğ—»ğ—´ğ—¶ğ—»ğ—²
async def process_content(file_bytes, file_type, user_config):
    """Next-gen processing pipeline"""
    def _sync_processing():
        # OCR Processing
        text = pytesseract.image_to_string(
            enhance_image(Image.open(io.BytesIO(file_bytes)) if file_type == 'image' 
            else convert_from_bytes(file_bytes)[0],
            lang=user_config['language']
        )
        
        # Post-Processing
        text = re.sub(r'\s+', ' ', text).strip()
        return text[:100000]  # Safety limit

    return await asyncio.get_event_loop().run_in_executor(
        executor, _sync_processing
    )

# ğ—•ğ—¼ğ˜ ğ—›ğ—®ğ—»ğ—±ğ—¹ğ—²ğ—¿ğ˜€
async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Next-gen file handler with AI features"""
    user = update.effective_user
    try:
        # ğ—”ğ—±ğ˜ƒğ—®ğ—»ğ—°ğ—²ğ—± ğ—™ğ—¶ğ—¹ğ—² ğ—›ğ—®ğ—»ğ—±ğ—¹ğ—¶ğ—»ğ—´
        file = await (update.message.photo[-1] if update.message.photo 
                     else update.message.document).get_file()
        
        if file.file_size > Config.MAX_FILE_SIZE:
            await update.message.reply_text("ğŸ“ File too large! (Max 50MB)")
            return

        # ğ—£ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ğ—¶ğ—»ğ—´ ğ—¦ğ˜ğ—®ğ˜ğ˜‚ğ˜€
        msg = await update.message.reply_text("ğŸ” Supercharging OCR with AI...")
        
        # ğ—”ğ—œ-ğ—¢ğ—£ğ˜ğ—¶ğ—ºğ—¶ğ˜‡ğ—²ğ—± ğ—¢ğ—–ğ—¥
        text = await process_content(
            await file.download_as_bytearray(),
            'image' if update.message.photo else 'pdf',
            context.user_data.setdefault('config', {
                'language': 'eng',
                'ai_features': True
            })
        )

        # ğ—”ğ—œ ğ—˜ğ—»ğ—µğ—®ğ—»ğ—°ğ—²ğ—ºğ—²ğ—»ğ˜ğ˜€
        if Config.AI_FEATURES['translation']:
            translated = await ai_translate(text)
            await update.message.reply_text(f"ğŸŒ Translation:\n{translated}")
        
        if Config.AI_FEATURES['summarization']:
            summary = await ai_summarize(text)
            await update.message.reply_text(f"ğŸ“ Summary:\n{summary}")

        # ğ—™ğ—¶ğ—»ğ—®ğ—¹ ğ—¢ğ˜‚ğ˜ğ—½ğ˜‚ğ˜
        await update.message.reply_text(f"âœ… Extracted Text:\n{text[:3000]}...")
        await context.bot.delete_message(chat_id=update.message.chat_id, message_id=msg.message_id)

    except Exception as e:
        logger.error(f"AI Processing Error: {e}")
        await update.message.reply_text("âš ï¸ AI Enhancement Failed. Sending raw OCR...")
        await handle_document(update, context)  # Fallback

# ğ— ğ—®ğ—¶ğ—» ğ—”ğ—½ğ—½ğ—¹ğ—¶ğ—°ğ—®ğ˜ğ—¶ğ—¼ğ—»
def main():
    app = Application.builder().token(os.getenv("7631499563:AAE3Mw3WY-05k3jiHxxUGElLCdII5YwbCKU")).build()
    
    # ğ—–ğ—¼ğ—ºğ—ºğ—®ğ—»ğ—±ğ˜€
    app.add_handler(CommandHandler("start", ...))  # Enhanced help
    app.add_handler(CommandHandler("ai", ...))    # Toggle AI features
    
    # ğ— ğ—²ğ˜€ğ˜€ğ—®ğ—´ğ—² ğ—›ğ—®ğ—»ğ—±ğ—¹ğ—²ğ—¿ğ˜€
    app.add_handler(MessageHandler(
        filters.PHOTO | filters.Document.ALL, 
        handle_file
    ))
    
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
